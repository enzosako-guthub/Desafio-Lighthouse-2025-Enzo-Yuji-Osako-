{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Tratamento de dados para nosso setup**\n",
        "\n",
        "Nessa etapa, basicamente estamos preparando nossos dados, assim como feito no EDA. Dessa maneira, evitamos potenciais erros na nossa modelagem."
      ],
      "metadata": {
        "id": "sygLpwuekClr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('desafio_indicium_imdb.csv')\n",
        "\n",
        "# Linha de código paliativo, evitando a criação de um índice antigo.\n",
        "if 'Unnamed: 0' in df.columns:\n",
        "    df = df.drop('Unnamed: 0', axis=1)\n",
        "\n",
        "# Corrigindo 'Runtime' e 'Gross'.\n",
        "df['Runtime'] = df['Runtime'].str.replace(' min', '').astype(int)\n",
        "\n",
        "df['Gross'] = df['Gross'].str.replace(',', '', regex=False)\n",
        "df['Gross'] = pd.to_numeric(df['Gross'], errors='coerce')\n",
        "\n",
        "# Corrigindo 'Released_Year'.\n",
        "df['Released_Year'] = pd.to_numeric(df['Released_Year'], errors='coerce')\n",
        "df.loc[df['Series_Title'] == 'Apollo 13', 'Released_Year'] = 1995\n",
        "\n",
        "# Imputação.\n",
        "median_year = df['Released_Year'].median()\n",
        "df['Released_Year'] = df['Released_Year'].fillna(median_year)\n",
        "\n",
        "df['Certificate'] = df['Certificate'].fillna('Not Rated')\n",
        "\n",
        "median_meta_score = df['Meta_score'].median()\n",
        "df['Meta_score'] = df['Meta_score'].fillna(median_meta_score)\n",
        "\n",
        "median_gross = df['Gross'].median()\n",
        "df['Gross'] = df['Gross'].fillna(median_gross)\n",
        "\n",
        "# Garantindo que o ano seja um número inteiro.\n",
        "df['Released_Year'] = df['Released_Year'].astype(int)\n",
        "#Verificando se a preparação de dados foi bem-sucedida.\n",
        "df.info()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdcQ3Kel4uK4",
        "outputId": "dca25ed5-492c-4e06-9d5e-005318bb5021"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 999 entries, 0 to 998\n",
            "Data columns (total 15 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Series_Title   999 non-null    object \n",
            " 1   Released_Year  999 non-null    int64  \n",
            " 2   Certificate    999 non-null    object \n",
            " 3   Runtime        999 non-null    int64  \n",
            " 4   Genre          999 non-null    object \n",
            " 5   IMDB_Rating    999 non-null    float64\n",
            " 6   Overview       999 non-null    object \n",
            " 7   Meta_score     999 non-null    float64\n",
            " 8   Director       999 non-null    object \n",
            " 9   Star1          999 non-null    object \n",
            " 10  Star2          999 non-null    object \n",
            " 11  Star3          999 non-null    object \n",
            " 12  Star4          999 non-null    object \n",
            " 13  No_of_Votes    999 non-null    int64  \n",
            " 14  Gross          999 non-null    float64\n",
            "dtypes: float64(3), int64(3), object(9)\n",
            "memory usage: 117.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Preparação de Dados para Modelagem**\n",
        "\n",
        "Nessa etapa, nós vamos separar nossos dados em dois grupos :     \n",
        "\n",
        "- Variáveis Preditoras (Features) : O `x`, são características do filme que acreditamos que contêm informações para prever a nota. Na minha modelagem, escolhi `Released_Year`, `Runtime`, `Meta_score`, `No_of_Votes` e `Gross`.\n",
        "\n",
        "- Variável Alvo (Target) : O `y`, é o que queremos que nosso modelo aprenda a prever. Nesse caso, `IMDB_Rating`.\n",
        "\n",
        "Notar ainda que resolvi separar meu **sample** em dois, com 80% sendo voltados para amostras de **treino**, permitindo que nosso modelo possa aprender os padrões de forma robusta e suficiente, e 20% sendo voltados para amostras de **teste**, de forma a testar a performance final do modelo.\n",
        "\n",
        "Por fim, devemos observar que as variáveis categóricas contam com centenas de valores únicos, o que tornaria nosso problema de modelagem bastante complexo dada sua grande cardinalidade, desse modo, resolvi manter apenas as 50 categorias mais frequentes (por exemplo, os 50 diretores mais comuns), agrupando o restante em uma única categoria chamada de \"Other\".\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gfhU9rUhm1sR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Selecionando Features e Alvo\n",
        "features = ['Released_Year', 'Runtime', 'Meta_score', 'No_of_Votes', 'Gross', 'Director', 'Star1', 'Genre']\n",
        "target = 'IMDB_Rating'\n",
        "\n",
        "X = df[features].copy()\n",
        "y = df[target]\n",
        "\n",
        "# 2. Limitando a cardinalidade para evitar excesso de colunas.\n",
        "for col in ['Director', 'Star1', 'Genre']:\n",
        "    top_categories = X[col].value_counts().nlargest(50).index\n",
        "    X.loc[:, col] = X[col].where(X[col].isin(top_categories), 'Other')\n",
        "\n",
        "# 3. Divisão em Dados de Treino e de Teste\n",
        "# Separação de 20% dos dados para teste, para avaliar o modelo final de forma imparcial.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"Dados de treino: {X_train.shape[0]} amostras\")\n",
        "print(f\"Dados de teste: {X_test.shape[0]} amostras\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7od_eagn7Cy",
        "outputId": "a3b4c93f-5e87-42d3-ba85-5f72aa3469df"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados de treino: 799 amostras\n",
            "Dados de teste: 200 amostras\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Criação de um Pipeline de Pré-Processamento.**\n",
        "\n",
        "Nessa etapa, utilizarei de um `Pipeline` para cuidar do pré-processamento, garantindo desse modo que minhas transformações ocorram de forma automática, além de evitar problemas de vazamento de dados.\n",
        "\n",
        "Como citado anteriormente, as variáveis categóricas, `Director`, `Genre` e `Star1`, possuem centenas de valores únicos, sendo dados de texto, cujos modelos não conseguem processar diretamente. Desse modo, foi necessário utilizar de uma técnica de **One-Hot Encoding**, basicamente transformando essas 3 categorias em vetores numéricos binários, com cada categoria tornando-se uma nova coluna com valores de 0 ou 1."
      ],
      "metadata": {
        "id": "l7Xu5a_5rOgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Definindo colunas numéricas e categóricas\n",
        "categorical_features = ['Director', 'Star1', 'Genre']\n",
        "numeric_features = ['Released_Year', 'Runtime', 'Meta_score', 'No_of_Votes', 'Gross']\n",
        "\n",
        "# Aplicando o OneHotEncoder\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', 'passthrough', numeric_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features) # sparse_output=False para facilitar a integração com alguns modelos\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "X0s5s5RGr2dl"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Baseline**\n",
        "\n",
        "É nessa etapa que podemos responder mais uma das questões do Desafio :     \n",
        "\n",
        "**Qual tipo de problema estamos resolvendo (Regressão ou Classificação)?**\n",
        "\n",
        "Como já deve ter ficado claro, trata-se de um problema de **regressão** devido a natureza da nossa variável alvo `y`, como sendo um valor numérico contínuo, nesse caso, o `IMDB_Rating`.\n",
        "\n",
        "É nesse sentido que nessa etapa utilizarei uma abordagem em que testarei vários **algortimos de regressão**, comparando suas performances usando uma técnica de **Cross-Validation**. Como métrica, utilizei o **Erro Médio Absoluto (MAE)**, por ser mais simples de interpretar.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-_whO2vBwL2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline de modelos de regressão\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# Lista de modelos para teste\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'K-Nearest Neighbors': KNeighborsRegressor(),\n",
        "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
        "    'Random Forest': RandomForestRegressor(random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "# Loop para treino e avaliação de cada modelo\n",
        "for name, model in models.items():\n",
        "    model_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', model)\n",
        "    ])\n",
        "\n",
        "    # Etapa de Cross-Validation\n",
        "    scores = cross_val_score(model_pipeline, X_train, y_train, cv=5, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
        "\n",
        "    # Armazenamos o MAE médio (notar que vamos inverter o sinal)\n",
        "    results[name] = -np.mean(scores)\n",
        "    print(f\"Modelo: {name} | MAE Médio (CV): {-np.mean(scores):.4f}\")\n",
        "\n",
        "# Exibição do melhor modelo\n",
        "best_model_name = min(results, key=results.get)\n",
        "print(f\"\\n✅ Melhor modelo no baseline: {best_model_name} com MAE de {results[best_model_name]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uPqdrmbyD-z",
        "outputId": "cfdf4b8c-407d-4a1e-8326-c389ac7719ce"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo: Linear Regression | MAE Médio (CV): 0.1716\n",
            "Modelo: K-Nearest Neighbors | MAE Médio (CV): 0.2304\n",
            "Modelo: Decision Tree | MAE Médio (CV): 0.1931\n",
            "Modelo: Random Forest | MAE Médio (CV): 0.1507\n",
            "Modelo: Gradient Boosting | MAE Médio (CV): 0.1483\n",
            "\n",
            "✅ Melhor modelo no baseline: Gradient Boosting com MAE de 0.1483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com o resultado em mãos, notamos que **Random Forest** e **Gradient Boosting**, que são modelos de **ensemble** apresentam os dois menores valores de MAE Médio, indicando desempenho muito superior em relação aos modelos mais simples.\n",
        "\n",
        "Afim de resolução do desafio, optei pela escolha do **Random Forest**, apesar do Gradient Boosting ter apresentado o menor MAE médio absoluto, isso porque ele possui uma implementação relativamente mais simples em comparação com o Gradient Boosting."
      ],
      "metadata": {
        "id": "8p5gATynzH_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Treinamento e Avaliação do Modelo Final**\n",
        "\n",
        "Nessa etapa, vamos treinar e avaliar o modelo vencedor, no caso, o **Random Forest**."
      ],
      "metadata": {
        "id": "AEqnNDeJ48cd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Criação do pipeline final com o modelo que escolhemos a partir do baseline.\n",
        "model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
        "])\n",
        "\n",
        "# Treinamento com o conjunto de treino.\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Avaliação final no conjunto de teste, que o modelo nunca viu.\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "# Cálculo das métricas finais\n",
        "mae = mean_absolute_error(y_test, y_pred_test)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "r2 = r2_score(y_test, y_pred_test)\n",
        "\n",
        "\n",
        "print(f\"Erro Médio Absoluto (MAE): {mae:.4f}\")\n",
        "print(f\"Raiz do Erro Quadrático Médio (RMSE): {rmse:.4f}\")\n",
        "print(f\"Coeficiente de Determinação (R²): {r2:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBzZEqLs486k",
        "outputId": "74e6bf40-3220-4e57-bc42-74fb82eaa56b"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro Médio Absoluto (MAE): 0.1541\n",
            "Raiz do Erro Quadrático Médio (RMSE): 0.1986\n",
            "Coeficiente de Determinação (R²): 0.3990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Teste do Modelo escolhido**\n",
        "\n",
        "Por fim, vamos resolver a questão do Desafio em que devemos prever a nota IMDB do filme dado, utilizando o nosso modelo escolhido e treinado."
      ],
      "metadata": {
        "id": "stffblIU1HYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Dados do filme\n",
        "new_movie_data = {\n",
        "    'Released_Year': 1994,\n",
        "    'Runtime': 142,\n",
        "    'Meta_score': 80.0,\n",
        "    'No_of_Votes': 2343110,\n",
        "    'Gross': 28341469.0,\n",
        "    'Director': 'Frank Darabont',\n",
        "    'Star1': 'Tim Robbins',\n",
        "    'Genre': 'Drama'\n",
        "}\n",
        "new_movie_df = pd.DataFrame([new_movie_data])\n",
        "\n",
        "# Aplicação da limitação de cardinalidade\n",
        "for col in ['Director', 'Star1', 'Genre']:\n",
        "    top_categories = X[col].value_counts().nlargest(50).index\n",
        "    if new_movie_df[col].iloc[0] not in top_categories:\n",
        "        new_movie_df.loc[0, col] = 'Other'\n",
        "\n",
        "# Fazendo a previsão com o modelo treinado na célula anterior\n",
        "predicted_rating = model.predict(new_movie_df[features])\n",
        "final_score = predicted_rating[0]\n",
        "\n",
        "print(f\"A nota do IMDB prevista para o filme 'The Shawshank Redemption' é: {final_score:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aVFWnbgk5qYr",
        "outputId": "c02de36e-60a4-47f2-c002-194be0322b9e"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A nota do IMDB prevista para o filme 'The Shawshank Redemption' é: 8.77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Salvando o modelo em formato .pkl**"
      ],
      "metadata": {
        "id": "SljAehZP7P-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "filename = 'imdb_rating_predictor.pkl'\n",
        "\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(model, f)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "l3c4m-4T7Urk"
      },
      "execution_count": 53,
      "outputs": []
    }
  ]
}